{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rDvdcfhOT_Jw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import gzip\n",
        "import struct\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
        "sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))))\n",
        "import custom_loaders\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "from prettytable import PrettyTable\n",
        "# import wandb\n",
        "# import conv_layers\n",
        "\n",
        "# from utils import count_parameters\n",
        "def count_parameters(model, print_table = False):\n",
        "\n",
        "    total_params = 0\n",
        "    if(print_table):\n",
        "        table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        params = parameter.numel()\n",
        "\n",
        "        if(print_table):\n",
        "            table.add_row([name, params])\n",
        "        total_params += params\n",
        "\n",
        "    if(print_table):\n",
        "        print(table)\n",
        "\n",
        "    if total_params/1e9 > 1:\n",
        "        print(f\"Total Trainable Params: {total_params/1e9} B\")\n",
        "    else:\n",
        "        print(f\"Total Trainable Params: {total_params/1e6} M\")\n",
        "\n",
        "    return total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dQIXd_-9lclx"
      },
      "outputs": [],
      "source": [
        "# !wget https://huggingface.co/datasets/student/celebA/resolve/main/Dataset.zip?download=true\n",
        "# !unzip -q Dataset.zip?download=truea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-snmw1MkDAb",
        "outputId": "94265add-8eb0-45af-90de-6e9d433794ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-01 07:29:19--  http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Resolving fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)... 52.219.170.224, 52.219.168.24, 52.219.170.188, ...\n",
            "Connecting to fashion-mnist.s3-website.eu-central-1.amazonaws.com (fashion-mnist.s3-website.eu-central-1.amazonaws.com)|52.219.170.224|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26421880 (25M) [binary/octet-stream]\n",
            "Saving to: ‘train-images-idx3-ubyte.gz’\n",
            "\n",
            "train-images-idx3-u 100%[===================>]  25.20M  11.3MB/s    in 2.2s    \n",
            "\n",
            "2024-01-01 07:29:22 (11.3 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [26421880/26421880]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "\n",
        "with gzip.open('train-images-idx3-ubyte.gz','rb') as f:\n",
        "    magic, size = struct.unpack(\">II\", f.read(8))\n",
        "    nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
        "    fmnist = np.frombuffer(f.read(), dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
        "    fmnist = fmnist.reshape((size, nrows, ncols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Fp05rTZ3lcl8"
      },
      "outputs": [],
      "source": [
        "## Time Embed\n",
        "\n",
        "class EmbedTime(nn.Module):\n",
        "    def __init__(self, input_d, time_d):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.Linear(input_d, time_d)\n",
        "        self.ln2 = nn.Linear(time_d, time_d)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.ln1(x)\n",
        "        x = self.ln2(self.relu(x))\n",
        "        return x\n",
        "\n",
        "def sinosoid_embed(edim, t_max):\n",
        "    pos_emb = torch.zeros((t_max, edim))\n",
        "    for pos in range(t_max):\n",
        "        for i in range(edim//2):\n",
        "            pos_emb[pos, 2*i] = np.sin(pos/(10000**(2*i/edim)))\n",
        "            pos_emb[pos, 2*i + 1] = np.cos(pos/(10000**(2*i/edim)))\n",
        "\n",
        "    return pos_emb.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "87S4AWPPVyDl"
      },
      "outputs": [],
      "source": [
        "class MyBlock(nn.Module):\n",
        "    def __init__(self, shape, in_c, out_c, kernel_size=3, stride=1, padding=1, activation=None, normalize=True):\n",
        "        super(MyBlock, self).__init__()\n",
        "        self.ln = nn.LayerNorm(shape)\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size, stride, padding)\n",
        "        self.activation = nn.SiLU() if activation is None else activation\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.ln(x) if self.normalize else x\n",
        "        out = self.conv1(out)\n",
        "        out = self.activation(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MyUNet(nn.Module):\n",
        "    def __init__(self, n_steps=1000, time_emb_dim=100):\n",
        "        super(MyUNet, self).__init__()\n",
        "\n",
        "        # Sinusoidal embedding\n",
        "        self.time_embed = nn.Embedding(n_steps, time_emb_dim)\n",
        "        self.time_embed.weight.data = sinosoid_embed(n_steps, time_emb_dim)\n",
        "        self.time_embed.requires_grad_(False)\n",
        "\n",
        "        # First half\n",
        "        self.te1 = self._make_te(time_emb_dim, 1)\n",
        "        self.b1 = nn.Sequential(\n",
        "            MyBlock((1, 28, 28), 1, 10),\n",
        "            MyBlock((10, 28, 28), 10, 10),\n",
        "            MyBlock((10, 28, 28), 10, 10)\n",
        "        )\n",
        "        self.down1 = nn.Conv2d(10, 10, 4, 2, 1)\n",
        "\n",
        "        self.te2 = self._make_te(time_emb_dim, 10)\n",
        "        self.b2 = nn.Sequential(\n",
        "            MyBlock((10, 14, 14), 10, 20),\n",
        "            MyBlock((20, 14, 14), 20, 20),\n",
        "            MyBlock((20, 14, 14), 20, 20)\n",
        "        )\n",
        "        self.down2 = nn.Conv2d(20, 20, 4, 2, 1)\n",
        "\n",
        "        self.te3 = self._make_te(time_emb_dim, 20)\n",
        "        self.b3 = nn.Sequential(\n",
        "            MyBlock((20, 7, 7), 20, 40),\n",
        "            MyBlock((40, 7, 7), 40, 40),\n",
        "            MyBlock((40, 7, 7), 40, 40)\n",
        "        )\n",
        "        self.down3 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, 2, 1),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(40, 40, 4, 2, 1)\n",
        "        )\n",
        "\n",
        "        # Bottleneck\n",
        "        self.te_mid = self._make_te(time_emb_dim, 40)\n",
        "        self.b_mid = nn.Sequential(\n",
        "            MyBlock((40, 3, 3), 40, 20),\n",
        "            MyBlock((20, 3, 3), 20, 20),\n",
        "            MyBlock((20, 3, 3), 20, 40)\n",
        "        )\n",
        "\n",
        "        # Second half\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(40, 40, 4, 2, 1),\n",
        "            nn.SiLU(),\n",
        "            nn.ConvTranspose2d(40, 40, 2, 1)\n",
        "        )\n",
        "\n",
        "        self.te4 = self._make_te(time_emb_dim, 80)\n",
        "        self.b4 = nn.Sequential(\n",
        "            MyBlock((80, 7, 7), 80, 40),\n",
        "            MyBlock((40, 7, 7), 40, 20),\n",
        "            MyBlock((20, 7, 7), 20, 20)\n",
        "        )\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(20, 20, 4, 2, 1)\n",
        "        self.te5 = self._make_te(time_emb_dim, 40)\n",
        "        self.b5 = nn.Sequential(\n",
        "            MyBlock((40, 14, 14), 40, 20),\n",
        "            MyBlock((20, 14, 14), 20, 10),\n",
        "            MyBlock((10, 14, 14), 10, 10)\n",
        "        )\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(10, 10, 4, 2, 1)\n",
        "        self.te_out = self._make_te(time_emb_dim, 20)\n",
        "        self.b_out = nn.Sequential(\n",
        "            MyBlock((20, 28, 28), 20, 10),\n",
        "            MyBlock((10, 28, 28), 10, 10),\n",
        "            MyBlock((10, 28, 28), 10, 10, normalize=False)\n",
        "        )\n",
        "\n",
        "        self.conv_out = nn.Conv2d(10, 1, 3, 1, 1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # x is (N, 2, 28, 28) (image with positional embedding stacked on channel dimension)\n",
        "        t = self.time_embed(t)\n",
        "        n = len(x)\n",
        "        out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))  # (N, 10, 28, 28)\n",
        "        out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))  # (N, 20, 14, 14)\n",
        "        out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))  # (N, 40, 7, 7)\n",
        "\n",
        "        out_mid = self.b_mid(self.down3(out3) + self.te_mid(t).reshape(n, -1, 1, 1))  # (N, 40, 3, 3)\n",
        "\n",
        "        out4 = torch.cat((out3, self.up1(out_mid)), dim=1)  # (N, 80, 7, 7)\n",
        "        out4 = self.b4(out4 + self.te4(t).reshape(n, -1, 1, 1))  # (N, 20, 7, 7)\n",
        "\n",
        "        out5 = torch.cat((out2, self.up2(out4)), dim=1)  # (N, 40, 14, 14)\n",
        "        out5 = self.b5(out5 + self.te5(t).reshape(n, -1, 1, 1))  # (N, 10, 14, 14)\n",
        "\n",
        "        out = torch.cat((out1, self.up3(out5)), dim=1)  # (N, 20, 28, 28)\n",
        "        out = self.b_out(out + self.te_out(t).reshape(n, -1, 1, 1))  # (N, 1, 28, 28)\n",
        "\n",
        "        out = self.conv_out(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def _make_te(self, dim_in, dim_out):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(dim_in, dim_out),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim_out, dim_out)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "cXldXQemlcl9"
      },
      "outputs": [],
      "source": [
        "## UNet\n",
        "\n",
        "class Down2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, time_d):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
        "        self.linear_time = nn.Linear(time_d, in_channels)\n",
        "        self.norm1 = nn.GroupNorm(8,out_channels)\n",
        "        self.norm2 = nn.GroupNorm(8,out_channels)\n",
        "        self.relu = nn.SiLU()\n",
        "\n",
        "    def forward(self, x, time):\n",
        "\n",
        "        time = self.linear_time(time).unsqueeze(-1).unsqueeze(-1)\n",
        "        x = x + time\n",
        "        x = self.norm1(self.relu(self.conv1(x)))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.norm2(self.relu(self.conv3(x)))\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Up2d(nn.Module):\n",
        "    def __init__(self, in_channels,out_channels, time_d):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels,in_channels//2, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels//2,in_channels//2, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels//2,in_channels//2, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels//2, out_channels, 3, padding=1)\n",
        "        self.linear_time = nn.Linear(time_d, in_channels)\n",
        "        self.norm1 = nn.GroupNorm(8,in_channels//2)\n",
        "        self.norm2 = nn.GroupNorm(8,in_channels//2)\n",
        "        self.relu = nn.SiLU()\n",
        "\n",
        "\n",
        "    def forward(self, x, time):\n",
        "\n",
        "        time = self.linear_time(time).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        x = x + time\n",
        "\n",
        "        x = self.norm1(self.relu(self.conv1(x)))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.norm2(self.relu(self.conv3(x)))\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class DownBlock2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, time_d):\n",
        "      super().__init__()\n",
        "\n",
        "      self.d1 = Down2d(in_channels, out_channels, time_d)\n",
        "      self.d2 = Down2d(out_channels, out_channels, time_d)\n",
        "      self.d3 = Down2d(out_channels, out_channels, time_d)\n",
        "      self.d4 = Down2d(out_channels, out_channels, time_d)\n",
        "\n",
        "    def forward(self, x, time):\n",
        "\n",
        "      x = self.d1(x, time)\n",
        "      x = self.d2(x, time)\n",
        "      x = self.d3(x, time)\n",
        "      x = self.d4(x, time)\n",
        "\n",
        "      return x\n",
        "\n",
        "class UpBlock2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, time_d):\n",
        "      super().__init__()\n",
        "\n",
        "      self.u1 = Up2d(in_channels, in_channels, time_d)\n",
        "      self.u2 = Up2d(in_channels, in_channels, time_d)\n",
        "      self.u3 = Up2d(in_channels, in_channels, time_d)\n",
        "      self.u4 = Up2d(in_channels, out_channels, time_d)\n",
        "\n",
        "    def forward(self, x, time):\n",
        "\n",
        "      x = self.u1(x, time)\n",
        "      x = self.u2(x, time)\n",
        "      x = self.u3(x, time)\n",
        "      x = self.u4(x, time)\n",
        "\n",
        "      return x\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, time_d):\n",
        "        super().__init__()\n",
        "\n",
        "        self.down_blocks = nn.ModuleList([DownBlock2d(i[0], i[1], time_d) for i in in_channels])\n",
        "        self.up_blocks = nn.ModuleList([UpBlock2d(i[0], i[1], time_d) for i in out_channels])\n",
        "\n",
        "        self.time_embed = EmbedTime(time_d, time_d)\n",
        "        self.midconv1 = nn.Conv2d(in_channels[-1][1], in_channels[-1][1], 3, padding=1)\n",
        "        self.midconv2 = nn.Conv2d(in_channels[-1][1], in_channels[-1][1], 3, padding=1)\n",
        "        self.relu = nn.SiLU()\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "\n",
        "    def forward(self, x, time):\n",
        "\n",
        "        time = self.time_embed(time)\n",
        "        downs = []\n",
        "        for block in self.down_blocks:\n",
        "            x = block(x, time)\n",
        "            downs.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.midconv2(self.relu(self.midconv1(x)))\n",
        "\n",
        "        for idx, block in enumerate(self.up_blocks):\n",
        "            x = self.upsample(x)\n",
        "            down = downs[-idx-1]\n",
        "            diff = down.shape[2] - x.shape[2]\n",
        "\n",
        "            x = nn.functional.pad(x, (diff, 0, diff, 0))\n",
        "            x = torch.concat((down, x), axis=1)\n",
        "            x = block(x, time)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3mK2XP3Vlcl-"
      },
      "outputs": [],
      "source": [
        "# in_channels = [3,64,128,256]\n",
        "# out_channels =  [(512, 128),(256, 64), (128, 3)]\n",
        "# time_d = 512\n",
        "\n",
        "# # unet = UNet(in_channels, out_channels, time_d)\n",
        "# # time_embed = EmbedTime(512, 512)\n",
        "\n",
        "# # time = torch.rand((1,512))\n",
        "# time = times[:, 3]\n",
        "# img = torch.rand((1,3,64,64))\n",
        "\n",
        "# time = time_embed(time)\n",
        "# a = unet(img, time)\n",
        "# print(a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Q7cfMKprlcl-"
      },
      "outputs": [],
      "source": [
        "betas = np.linspace(0.0001, 0.02, 1000)\n",
        "alphas = [1-beta for beta in betas]\n",
        "\n",
        "alphas_cumprod = [alphas[0]]\n",
        "for alpha in alphas[1:]:\n",
        "    alphas_cumprod.append(alphas_cumprod[-1]*alpha)\n",
        "\n",
        "alphas_cumprod_prev = alphas_cumprod[:-1]\n",
        "\n",
        "betas = torch.tensor(betas)\n",
        "alphas = torch.tensor(alphas)\n",
        "alphas_cumprod = torch.tensor(alphas_cumprod)\n",
        "alphas_cumprod_prev = torch.tensor(alphas_cumprod_prev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GMsR_Nqalcl-"
      },
      "outputs": [],
      "source": [
        "def get_x_t(t, x_0, alpha_bars):\n",
        "    eps_t = np.random.normal(size = x_0.shape)\n",
        "    x_t = np.sqrt(alpha_bars[t-1])*x_0 + np.sqrt(1 - alphas_cumprod[t-1])*eps_t\n",
        "\n",
        "    return x_t, eps_t\n",
        "\n",
        "def get_x_t_all(x, betas):\n",
        "    imgs = []\n",
        "    for beta_t in tqdm(betas):\n",
        "        eps_t = np.random.normal(size = x.shape)\n",
        "        alpha_t = 1 - beta_t\n",
        "        x = np.sqrt(alpha_t)*x.copy() + (np.sqrt(1 - alpha_t))*eps_t\n",
        "        imgs.append(x)\n",
        "\n",
        "    return imgs\n",
        "\n",
        "def get_noisy_imgs_t(x_0, alpha_bars, device=\"cpu\"):\n",
        "\n",
        "    bs = x_0.shape[0]\n",
        "    t_steps = torch.randint(0,1000, (bs,))\n",
        "\n",
        "    eps_t = torch.normal(0,1,size = x_0.shape).to(device)\n",
        "\n",
        "    alpha_bars_t = alphas_cumprod[t_steps].unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).to(device)\n",
        "\n",
        "    x_t = torch.sqrt(alpha_bars_t)*x_0 + torch.sqrt(1 - alpha_bars_t)*eps_t\n",
        "\n",
        "    return x_t, t_steps, eps_t\n",
        "\n",
        "def plot_grid(tensor, n_rows=4, n_cols=4):\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5, 5))\n",
        "    for i in range(n_rows):\n",
        "        for j in range(n_cols):\n",
        "            axes[i, j].imshow(tensor[i*n_cols+j][0].numpy(), cmap='gray')\n",
        "            axes[i, j].set_axis_off()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "### Sampling\n",
        "\n",
        "def sample_ddim(unet, n_samples = 16):\n",
        "\n",
        "  unet.eval()\n",
        "  x = torch.normal(0,1,size=(n_samples,1,28,28)).to(device)\n",
        "\n",
        "  # imgs = []\n",
        "  # imgs.append(x)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for t in reversed(trange(1000)):\n",
        "        noise = unet(x, sin_times[t].to(device))\n",
        "\n",
        "        # noise = unet(x, torch.tensor([t]).repeat(n_samples).to(device).long())\n",
        "        a_t = alphas[t]\n",
        "        a_bar_t = alphas_cumprod[t]\n",
        "        x = (1/torch.sqrt(a_t))*(x - ((1 - a_t)*noise)/torch.sqrt(1 - a_bar_t))\n",
        "        if t != 0:\n",
        "          z = torch.normal(0,1,size=(n_samples,1,28,28)).to(device)\n",
        "          sigma = torch.sqrt((betas[t]*(1 - alphas_cumprod[t-1]))/(1 - alphas_cumprod[t]))\n",
        "          # sigma = torch.sqrt(betas[t])\n",
        "          x = x + sigma*z\n",
        "        # imgs.append(x)\n",
        "\n",
        "  print(torch.max(x), torch.min(x))\n",
        "  return x.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "X7FZN9jOlcl_"
      },
      "outputs": [],
      "source": [
        "# img = np.asarray(Image.open(\"cat.png\")).astype(np.float32)\n",
        "# img = (img/255 - 0.5)*2\n",
        "\n",
        "# img_t = get_x_t(200, img, alpha_bars)[0]\n",
        "# plt.imshow(img_t)\n",
        "\n",
        "# img = np.asarray(Image.open(\"cat.png\")).astype(np.float32)\n",
        "# img = (img/255 - 0.5)*2\n",
        "# img = torch.tensor(img).unsqueeze(0)\n",
        "# img_t = get_noisy_imgs_t(img, alpha_bars)[0]\n",
        "\n",
        "# plt.imshow(img_t[0])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0aNQLlKlcmA",
        "outputId": "6a44686e-58b3-48fc-dd02-59932310affa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60000/60000 [00:13<00:00, 4317.36it/s]\n"
          ]
        }
      ],
      "source": [
        "img_size = 28\n",
        "n_channels = 1\n",
        "num_imgs = None\n",
        "time_d = 100\n",
        "\n",
        "class Args():\n",
        "    def __init__(self):\n",
        "        self.dataset = 'GAN'\n",
        "        self.imgPath = 'CelebA_train/img_align_celeba'\n",
        "        self.imgSize = img_size\n",
        "        self.download = False\n",
        "        self.imgC = n_channels\n",
        "        self.num_images = num_imgs\n",
        "        self.convert2bw = False\n",
        "        self.images = fmnist\n",
        "\n",
        "args = Args()\n",
        "print(\"Loading data...\")\n",
        "train_dataset = custom_loaders.get_data_loader(args)\n",
        "sin_times = sinosoid_embed(1000, time_d)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2qyC7uElcmB",
        "outputId": "69c0fefc-a956-4b57-fdeb-8362724c963a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Trainable Params: 1.619086 M\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1619086"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bs = 256\n",
        "lr = 1e-4\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# in_channels = [(1,32, True),(32,32, False),(32,32, True),(32,32, False), (32, 32,True), (32,32, False)]\n",
        "# out_channels =  [(64, 32, False),(64, 32, True), (64, 32, False),(64, 32, True),(64, 32, False),(64, 1, True)]\n",
        "\n",
        "# in_channels = [(1,64, True),(64,64, False),(64,128, True),(128,128, False), (128,128, True), (128,256, False)]\n",
        "# out_channels =  [(512, 128, False),(256, 128, True), (256, 128, False),(256, 64, True),(128, 64, False),(128, 1, True)]\n",
        "\n",
        "in_channels = [(1,32), (32,32), (32,32),(32, 32)]\n",
        "out_channels =  [(64, 32),(64, 32),(64, 32), (64, 1)]\n",
        "\n",
        "train_loader = data_utils.DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
        "\n",
        "unet = UNet(in_channels, out_channels, time_d).to(device)\n",
        "# unet = MyUNet(1000).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(unet.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "mse = nn.MSELoss()\n",
        "count_parameters(unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "Pr7LLGYmlcmB",
        "outputId": "ef4b5b34-0d17-4059-ad6c-84c4fb4d64fe"
      },
      "outputs": [],
      "source": [
        "n_epochs = 1\n",
        "log_idx = 100\n",
        "\n",
        "idx = 0\n",
        "unet.train()\n",
        "losses = []\n",
        "for epochs in range(n_epochs):\n",
        "    for data in tqdm(train_loader):\n",
        "        imgs = data.to(device)\n",
        "        noisy_imgs, t, noise = get_noisy_imgs_t(imgs, betas, device=device)\n",
        "        time = sin_times[t].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred_noise = unet(noisy_imgs.to(torch.float32).to(device), time)\n",
        "        # pred_noise = unet(noisy_imgs.to(torch.float32).to(device), t.to(device).long())\n",
        "\n",
        "        loss = mse(pred_noise, noise)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # idx+=1\n",
        "        # if idx%log_idx == 0:\n",
        "    print(np.mean(losses))\n",
        "    losses = []\n",
        "    plot_grid(sample_ddim(unet))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APofVvPalcmB"
      },
      "outputs": [],
      "source": [
        "x = imgs[700]\n",
        "\n",
        "print(torch.max(x), torch.min(x))\n",
        "# plt.plot(x.flatten().detach().cpu().numpy())\n",
        "plt.imshow(x.detach().cpu()[0].permute(1,2,0).numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be-g-K_3suH-"
      },
      "outputs": [],
      "source": [
        "# for data in tqdm(train_loader):\n",
        "  ## for data in tqdm(train_loader):\n",
        "  #   imgs = data.to(device)\n",
        "  #   noisy_imgs, t, noise = get_noisy_imgs_t(imgs, betas, device=device)\n",
        "  #   time = sin_times[t].to(device)\n",
        "  ## plt.imshow(data[0][0])\n",
        "  #   break\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
