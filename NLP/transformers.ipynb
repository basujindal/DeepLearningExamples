{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi\n",
    "# !git clone https://github.com/basujindal/CodeSnippets.git\n",
    "# !pip install transformers wandb\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tokenizers import decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import pickle\n",
    "from re import sub\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import time\n",
    "# from custom_transformer import CustomTransformer\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4442494\n"
     ]
    }
   ],
   "source": [
    "with open('../data/en_tokenized.pkl', 'rb') as f:\n",
    "    en_tokens = pickle.load(f)\n",
    "\n",
    "with open('../data/de_tokenized.pkl', 'rb') as f:\n",
    "    de_tokens = pickle.load(f)\n",
    "\n",
    "print(len(en_tokens))\n",
    "assert(len(de_tokens) == len(en_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_de = Tokenizer.from_file(\"tokenizer_de_25000_start_token_SOS.json\")\n",
    "tokenizer_en = Tokenizer.from_file(\"tokenizer_en_25000_start_token_SOS.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, h, edim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.h = h\n",
    "        self.edim = edim\n",
    "        self.dk = self.edim//self.h\n",
    "        self.key = nn.Linear(self.edim,self.edim)\n",
    "        self.query = nn.Linear(self.edim,self.edim)\n",
    "        self.value = nn.Linear(self.edim,self.edim)\n",
    "        self.linear = nn.Linear(self.edim,self.edim)\n",
    "        \n",
    "\n",
    "    def forward(self, key, value,query, mask = None):\n",
    "\n",
    "        bs = key.shape[0]\n",
    "        nwords_key = key.shape[1]\n",
    "        nwords_query = query.shape[1]\n",
    "\n",
    "        k = self.key(key).reshape(bs, nwords_key, self.h, self.dk).transpose(1,2)\n",
    "        q = self.query(query).reshape(bs, nwords_query, self.h, self.dk).transpose(1,2)\n",
    "        v = self.value(value).reshape(bs, nwords_key, self.h, self.dk).transpose(1,2)\n",
    "        x = torch.einsum('bhmd,bhnd -> bhmn',(q,k))\n",
    "        \n",
    "        if mask != None:\n",
    "            x = x.masked_fill(mask == False, float(\"-1e10\"))\n",
    "\n",
    "        x = F.softmax(x/(self.dk)**0.5, dim=3)\n",
    "\n",
    "        x = torch.einsum('bhmn,bhnv -> bhmv', (x,v))\n",
    "        x = x.transpose(1,2)\n",
    "\n",
    "        x = x.reshape(bs, nwords_query, -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, edim, h, hdim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.multiHeadAttention = MultiHeadAttention(h, edim)\n",
    "        self.norm1 = nn.LayerNorm(edim)\n",
    "        self.norm2 = nn.LayerNorm(edim)\n",
    "        self.fc1 = nn.Linear(edim, hdim)\n",
    "        self.fc2 = nn.Linear(hdim, edim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, src_embed, src_mask):\n",
    "\n",
    "        x = self.multiHeadAttention(src_embed,src_embed,src_embed, src_mask)\n",
    "        x = self.dropout1(x)\n",
    "        subLayer1 = self.norm1(x + src_embed)\n",
    "\n",
    "        x = self.fc2(self.relu(self.fc1(subLayer1)))\n",
    "        x = self.dropout2(x)\n",
    "        subLayer2 = self.norm2(x + subLayer1)\n",
    "\n",
    "        return subLayer2\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self,edim, h, hdim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.multiHeadAttention = MultiHeadAttention(h, edim)\n",
    "        self.maskedMultiHeadAttention = MultiHeadAttention(h, edim)\n",
    "        self.norm1 = nn.LayerNorm(edim)\n",
    "        self.norm2 = nn.LayerNorm(edim)\n",
    "        self.norm3 = nn.LayerNorm(edim)\n",
    "        self.fc1 = nn.Linear(edim, hdim)\n",
    "        self.fc2 = nn.Linear(hdim, edim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt_embed, src_encoded, src_mask, tgt_mask):\n",
    "\n",
    "        x = self.maskedMultiHeadAttention(tgt_embed, tgt_embed, tgt_embed, tgt_mask)\n",
    "        x = self.dropout1(x)\n",
    "        subLayer1 = self.norm1(x + tgt_embed)\n",
    "\n",
    "        x = self.multiHeadAttention(src_encoded, src_encoded, subLayer1, src_mask)\n",
    "        x = self.dropout2(x)\n",
    "        subLayer2 = self.norm2(x + subLayer1)\n",
    "\n",
    "        x = self.fc2(self.relu(self.fc1(subLayer2)))\n",
    "        x = self.dropout3(x)\n",
    "        subLayer3 = self.norm3(x + subLayer2)\n",
    "        \n",
    "        return subLayer3\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, nx, edim, h, hdim,dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nx = nx\n",
    "        self.transformers = nn.ModuleList([EncoderBlock(edim, h, hdim,dropout) for _ in range(nx)])\n",
    "\n",
    "    def forward(self, src_embed, src_mask):\n",
    "        for block in self.transformers:\n",
    "            embed = block(src_embed, src_mask)\n",
    "        return embed\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, nx, edim, h, hdim,dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nx = nx\n",
    "        self.transformers = nn.ModuleList([DecoderBlock(edim, h, hdim,dropout) for _ in range(nx)])\n",
    "\n",
    "    def forward(self, encoded, tgt_embed, src_mask, tgt_mask):\n",
    "\n",
    "        for block in self.transformers:\n",
    "            embed = block(tgt_embed, encoded, src_mask, tgt_mask)\n",
    "        return embed\n",
    "\n",
    "\n",
    "class CustomTransformer(nn.Module):\n",
    "    def __init__(self, nx, edim, h, hdim, dropout, src_vocab_size, tgt_vocab_size):\n",
    "        super().__init__()\n",
    "        self.tgt_vocab_size = tgt_vocab_size\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size,edim)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size,edim)\n",
    "        self.encoder = Encoder(nx, edim, h, hdim,dropout)\n",
    "        self.decoder = Decoder(nx, edim, h, hdim,dropout)\n",
    "        self.fc = nn.Linear(edim, tgt_vocab_size)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src_tokens, tgt_tokens, src_mask, tgt_mask, src_pos_embed, tgt_pos_embed, encoded = None):\n",
    "        \n",
    "        if encoded == None:\n",
    "\n",
    "            src_embed = self.src_embedding(src_tokens) + src_pos_embed\n",
    "            src_embed = self.dropout1(src_embed)\n",
    "            encoded = self.encoder(src_embed, src_mask)\n",
    "\n",
    "        tgt_embed = self.tgt_embedding(tgt_tokens) + tgt_pos_embed\n",
    "        tgt_embed = self.dropout2(tgt_embed)\n",
    "        \n",
    "        decoded = self.decoder(encoded, tgt_embed, src_mask, tgt_mask)\n",
    "        output = self.fc(decoded)\n",
    "\n",
    "        return output, encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(en_tokens, de_tokens, bs, src_pad_idx, tgt_pad_idx, device, shuffle = True):\n",
    "    num_batches = len(en_tokens)//bs\n",
    "    idxs = [i for i in range(num_batches)]\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(idxs)\n",
    "\n",
    "    for i in idxs:\n",
    "        max_len = len(en_tokens[(i+1)*bs - 1])\n",
    "        en_tensor = torch.tensor([enc.tolist() + \n",
    "        [src_pad_idx]*(max_len - len(enc)) for enc in en_tokens[i*bs:(i+1)*bs]], device=device)\n",
    "        \n",
    "        en_pad = torch.tensor((en_tensor != src_pad_idx),device=device).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        tgt_lens = [len(enc) for enc in de_tokens[i*bs:(i+1)*bs]]\n",
    "        max_len= max(tgt_lens)\n",
    "        tgt = torch.tensor([enc.tolist() + \n",
    "        [tgt_pad_idx]*(max_len - len(enc)) for enc in de_tokens[i*bs:(i+1)*bs]], device=device)\n",
    "        \n",
    "        de_mask = torch.ones(bs, max_len, max_len, device=device).tril().unsqueeze(1)\n",
    "\n",
    "        labels = torch.cat([tgt[ii][1:tgt_lens[ii]] for ii in range(tgt.shape[0])], dim = 0).to(device)\n",
    "\n",
    "        yield en_tensor, en_pad, tgt, de_mask, tgt_lens, labels\n",
    "\n",
    "\n",
    "def positionEmbeding(edim, max_nwords):\n",
    "    pos_emb = torch.zeros((max_nwords, edim))\n",
    "    for pos in range(max_nwords):\n",
    "        for i in range(edim//2):\n",
    "            pos_emb[pos, 2*i] = np.sin(pos/(10000**(2*i/edim)))\n",
    "            pos_emb[pos, 2*i + 1] = np.cos(pos/(10000**(2*i/edim)))\n",
    "\n",
    "    return pos_emb\n",
    "\n",
    "def remove_large_Sentences(en_tokens, de_tokens, max_size):\n",
    "    li = []\n",
    "    for i in range(len(en_tokens)):\n",
    "        if(len(en_tokens[i]) <= max_size and len(de_tokens[i]) <= max_size):\n",
    "            li.append(i)\n",
    "\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "\n",
    "    def __init__(self, model_size, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self):\n",
    "        return self.model_size ** (-0.5) *min(self._step ** (-0.5),  self._step * self.warmup ** (-1.5))\n",
    "\n",
    "def save_model(PATH):\n",
    "    state = {\n",
    "      'state_dict': net.state_dict(),\n",
    "      'optimizer': optimizer.state_dict(),\n",
    "      'scheduler_step': scheduler._step\n",
    "      }\n",
    "    torch.save(state, PATH)\n",
    "\n",
    "\n",
    "def validate(val_en_tokens, val_de_tokens, bs):\n",
    "\n",
    "    net.val()\n",
    "    correct, total = 0, 0\n",
    "    p_bar=tqdm(total=len(val_en_tokens)//bs)\n",
    "\n",
    "    for src, src_mask, tgt, tgt_mask, tgt_lens, labels in loader(val_en_tokens, val_de_tokens, bs, src_pad_idx, tgt_pad_idx, device):\n",
    "        p_bar.update(1)\n",
    "\n",
    "        src_pos_embed = posEmb[:src.shape[1]].unsqueeze(0)\n",
    "        tgt_pos_embed = posEmb[:tgt.shape[1]].unsqueeze(0)\n",
    "\n",
    "        outputs, _ = net(src, tgt, src_mask, tgt_mask, src_pos_embed, tgt_pos_embed)\n",
    "\n",
    "        li = [outputs[ii][:tgt_lens[ii]-1] for ii in range(outputs.shape[0])]\n",
    "        probs = torch.cat(li, dim = 0)\n",
    "        predicted = torch.max(probs, 1)[1]\n",
    "        \n",
    "        total = labels.size(0)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "nx = 6\n",
    "edim = 512\n",
    "hdim = 2048\n",
    "h = 8\n",
    "src_vocab_size = 25000\n",
    "tgt_vocab_size = 25000\n",
    "n_epochs = 10\n",
    "bs = 32\n",
    "src_pad_idx = 0\n",
    "tgt_pad_idx = 2\n",
    "dropout = 0.1\n",
    "max_nwords = 100\n",
    "n_epochs = 10\n",
    "val_steps = 10000\n",
    "val_accu = 0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "net = CustomTransformer(nx, edim, h, hdim, dropout, src_vocab_size, tgt_vocab_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), betas=[0.9, 0.98])\n",
    "scheduler = NoamOpt(edim,2500,optimizer)\n",
    "# scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "# PATH = \"saved_models/n_steps_\" + str(step)\n",
    "# state = torch.load(PATH)\n",
    "# net.load_state_dict(state['state_dict'])\n",
    "# optimizer.load_state_dict(state['optimizer'])\n",
    "# scheduler._step = state['scheduler_step']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idxs = remove_large_Sentences(en_tokens, de_tokens, max_nwords)\n",
    "en_tokens = [en_tokens[i] for i in max_idxs]\n",
    "de_tokens = [de_tokens[i] for i in max_idxs]\n",
    "assert(len(de_tokens) == len(en_tokens))\n",
    "posEmb = positionEmbeding(edim, max_nwords).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbasujindal\u001b[0m (\u001b[33mbasujindal123\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/data/DeepLearningExamples/NLP/wandb/run-20230311_085006-5185z0nh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/basujindal123/transformers/runs/5185z0nh\" target=\"_blank\">dazzling-lion-2</a></strong> to <a href=\"https://wandb.ai/basujindal123/transformers\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/basujindal123/transformers\" target=\"_blank\">https://wandb.ai/basujindal123/transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/basujindal123/transformers/runs/5185z0nh\" target=\"_blank\">https://wandb.ai/basujindal123/transformers/runs/5185z0nh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging = True\n",
    "log_steps = 512\n",
    "if logging:\n",
    "    wandb.init(project=\"transformers\", entity='basujindal123')\n",
    "    wandb.config = {\n",
    "    \"nsteps\": 0,\n",
    "    \"batch_size\": bs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34598 [00:00<?, ?it/s]/tmp/ipykernel_8569/322466881.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  en_pad = torch.tensor((en_tensor != src_pad_idx),device=device).unsqueeze(1).unsqueeze(2)\n",
      " 24%|██▎       | 8207/34598 [1:24:07<3:32:11,  2.07it/s]"
     ]
    }
   ],
   "source": [
    "bs = 128\n",
    "net.train()\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    p_bar=tqdm(total=len(en_tokens)//bs)\n",
    "  \n",
    "    for src, src_mask, tgt, tgt_mask, tgt_lens, labels in loader(en_tokens, de_tokens, bs, src_pad_idx, tgt_pad_idx, device):\n",
    "        p_bar.update(1)\n",
    "\n",
    "        step+=1\n",
    "        src_pos_embed = posEmb[:src.shape[1]].unsqueeze(0)\n",
    "        tgt_pos_embed = posEmb[:tgt.shape[1]].unsqueeze(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        outputs, _ = net(src, tgt, src_mask, tgt_mask, src_pos_embed, tgt_pos_embed)\n",
    "\n",
    "        li = [outputs[ii][:tgt_lens[ii]-1] for ii in range(outputs.shape[0])]\n",
    "        probs = torch.cat(li, dim = 0)\n",
    "        loss = criterion(probs, labels)   \n",
    "\n",
    "        if(step%100 == 0 and  np.isnan(loss.data.cpu().numpy())):\n",
    "            print(\"Loss is NaN\")\n",
    "            print(outputs)\n",
    "            break\n",
    "\n",
    "        # scaler.scale(loss).backward()\n",
    "        # scaler.step(optimizer)\n",
    "        # scaler.update()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        predicted = torch.max(probs, 1)[1]\n",
    "        \n",
    "        total = labels.size(0)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "\n",
    "        if step%2:\n",
    "            scheduler.step()\n",
    "\n",
    "        if (step&log_steps == 0) and logging:\n",
    "            try:\n",
    "                wandb.log(\n",
    "                    {\"loss\": loss.data,\n",
    "                    \"lr\": scheduler._rate,\n",
    "                    \"accuracy\": correct/(total+1),\n",
    "                    \"validation accuracy\": val_accu,\n",
    "                    })\n",
    "            except:\n",
    "                print(\"not logged\")\n",
    "                pass\n",
    "        \n",
    "        if(step%10000 == 0):\n",
    "            PATH = \"saved_models/n_steps_\" + str(step)\n",
    "            save_model(PATH)\n",
    "\n",
    "        \n",
    "        # if step % val_steps == 0: \n",
    "        #     val_accu = validate(val_en_tokens, val_de_tokens, bs)\n",
    "        #     print(\"step {0} | loss: {1:.4f} | Val Accuracy: {2:.3f} %\".format(epoch, loss, val_accu))\n",
    "\n",
    "        #     if val_accu > best_accu:\n",
    "        #       best_accu = val_accu \n",
    "        #       torch.save(net.state_dict(), 'net_val.pth')\n",
    "        #       print(\"Saving\")\n",
    "\n",
    "        #     net.train()\n",
    "\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positionEmbeding(edim, max_nwords):\n",
    "    pos_emb = torch.zeros((max_nwords, edim))\n",
    "    for pos in range(max_nwords):\n",
    "        for i in range(edim//2):\n",
    "            pos_emb[pos, 2*i] = np.sin(pos/(10000**(2*i/edim)))\n",
    "            pos_emb[pos, 2*i + 1] = np.cos(pos/(10000**(2*i/edim)))\n",
    "\n",
    "    return pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, net, device):\n",
    "\n",
    "    net.eval()\n",
    "    posEmb = positionEmbeding(edim, max_nwords).to(device)\n",
    "\n",
    "    src_enc = tokenizer_en.encode(sentence).ids\n",
    "    src = torch.tensor(src_enc, device=device).unsqueeze(0)\n",
    "    src_mask = None\n",
    "\n",
    "    tgt_enc = [0]\n",
    "    tgt = torch.tensor(tgt_enc, device=device).unsqueeze(0)\n",
    "    tgt_mask =  torch.ones(1, len(tgt), len(tgt),device=device).tril().unsqueeze(1)\n",
    "    \n",
    "\n",
    "\n",
    "    src_pos_embed = posEmb[:src.shape[1]].unsqueeze(0)\n",
    "    tgt_pos_embed = posEmb[:tgt.shape[1]].unsqueeze(0)\n",
    "\n",
    "    output, encoded = net(src, tgt, src_mask, tgt_mask, src_pos_embed, tgt_pos_embed)\n",
    "\n",
    "    _, predicted_idx = torch.max(output.data[0], 1)\n",
    "    print(tgt)\n",
    "    print(predicted_idx.tolist())\n",
    "    print(tokenizer_de.decode(predicted_idx.tolist()))\n",
    "\n",
    "\n",
    "    idx = 0\n",
    "    while(predicted_idx[-1].tolist() != 1):\n",
    "        \n",
    "        tgt = torch.cat((tgt, predicted_idx[-1].unsqueeze(0).unsqueeze(0)), 1)\n",
    "        tgt_mask =  torch.ones(1, tgt.shape[-1], tgt.shape[-1]).tril().unsqueeze(1).to(device)\n",
    "        # print(tgt)\n",
    "        # print(\"Hello\", tgt_mask)\n",
    "        output, _ = net(src, tgt, src_mask, tgt_mask, src_pos_embed, tgt_pos_embed, encoded)\n",
    "        _, predicted_idx = torch.max(output.data[0], 1)\n",
    "        print(predicted_idx.tolist())\n",
    "        print(tokenizer_de.decode(predicted_idx.tolist()))\n",
    "        idx+=1\n",
    "\n",
    "        if(idx == max_nwords):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positionEmbeding(edim, max_nwords):\n",
    "    pos_emb = torch.zeros((max_nwords, edim))\n",
    "    for pos in range(max_nwords):\n",
    "        for i in range(edim//2):\n",
    "            pos_emb[pos, 2*i] = np.sin(pos/(10000**(2*i/edim)))\n",
    "            pos_emb[pos, 2*i + 1] = np.cos(pos/(10000**(2*i/edim)))\n",
    "\n",
    "    return pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer\n",
    "import torch\n",
    "from re import sub\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from customTransformers import CustomTransformer \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "nx = 16\n",
    "edim = 512\n",
    "hdim = 2048\n",
    "h = 8\n",
    "src_vocab_size = 25000\n",
    "tgt_vocab_size = 25000\n",
    "pad_idx = 0\n",
    "dropout = 0.1\n",
    "max_nwords = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "net = CustomTransformer(nx, edim, h, hdim, dropout, src_vocab_size, tgt_vocab_size).to(device)\n",
    "\n",
    "PATH = \"/root/data/DeepLearningExamples/NLP/n_steps_63000.pth\"\n",
    "state = torch.load(PATH)\n",
    "net.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, net, device):\n",
    "\n",
    "    net.eval()\n",
    "    posEmb = positionEmbeding(edim, max_nwords).to(device)\n",
    "\n",
    "    src_enc = tokenizer_en.encode(sentence).ids\n",
    "    src = torch.tensor(src_enc, device=device).unsqueeze(0)\n",
    "    src_mask = None\n",
    "\n",
    "    tgt_enc = [0]\n",
    "    tgt = torch.tensor(tgt_enc, device=device).unsqueeze(0)\n",
    "    tgt_mask =  torch.ones(1, len(tgt), len(tgt),device=device).tril().unsqueeze(1)\n",
    "\n",
    "    src_pos_embed = posEmb[:src.shape[1]].unsqueeze(0)\n",
    "    tgt_pos_embed = posEmb[:tgt.shape[1]].unsqueeze(0)\n",
    "\n",
    "    output, encoded = net(src, tgt, src_mask, tgt_mask, src_pos_embed, tgt_pos_embed)\n",
    "\n",
    "    _, predicted_idx = torch.max(output.data[0], 1)\n",
    "\n",
    "\n",
    "    idx = 0\n",
    "    while(predicted_idx[-1].tolist() != 1):\n",
    "        \n",
    "        tgt = torch.cat((tgt, predicted_idx[-1].unsqueeze(0).unsqueeze(0)), 1)\n",
    "        tgt_mask =  torch.ones(1, tgt.shape[-1], tgt.shape[-1]).tril().unsqueeze(1).to(device)\n",
    "        output, _ = net(src, tgt, src_mask, tgt_mask, src_pos_embed, tgt_pos_embed, encoded)\n",
    "        _, predicted_idx = torch.max(output.data[0], 1)\n",
    "        idx+=1\n",
    "\n",
    "        if(idx == max_nwords):\n",
    "            break\n",
    "    print(predicted_idx.tolist())\n",
    "    print(tokenizer_de.decode(predicted_idx.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filePath = \"/root/data/DeepLearningExamples/NLP/\"\n",
    "tokenizer_en = Tokenizer.from_file(\"/root/data/DeepLearningExamples/data/en_hin/tokenizer_d1_25000.json\")\n",
    "tokenizer_de = Tokenizer.from_file(\"/root/data/DeepLearningExamples/data/en_hin/tokenizer_d2_25000.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2721, 550, 2721, 550, 415, 965, 1]\n",
      "आपका नाम आपका नाम क्या है?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"whats your name\"\n",
    "translate(sentence, net, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate BLEU score\n",
    "\n",
    "def bleu_score(outputs, targets):\n",
    "    return torchtext.data.metrics.bleu_score(outputs, targets)\n",
    "\n",
    "def calculate_bleu(data, net, device, max_nwords = 50):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    for sentence in data:\n",
    "        target = sentence[1:]\n",
    "        output = translate(sentence[0], net, device, max_nwords)\n",
    "        targets.append(target)\n",
    "        outputs.append(output)\n",
    "    return bleu_score(outputs, targets)\n",
    "\n",
    "print(\"BLEU score: \", calculate_bleu(val_en_tokens, net, device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('misc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1af58a0c390f807515830a18bbb19ac451fbe3aa00c4c733482807097ac6a02a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
